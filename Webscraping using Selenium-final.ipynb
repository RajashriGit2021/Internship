{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\sandip darveshi\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\sandip darveshi\\anaconda3\\lib\\site-packages (from selenium) (1.25.11)\n"
     ]
    }
   ],
   "source": [
    "#!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "chrome_options.add_experimental_option(\"excludeSwitches\",[\"enable-automation\"])\n",
    "driver = webdriver.Chrome(options=chrome_options,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "\n",
    "first get the webpage https://www.naukri.com/\n",
    "Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "Then click the search button.\n",
    "Then scrape the data for the first 10 jobs results you get.\n",
    "Finally create a dataframe of the scraped data. Note- All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first connect to the web driver through chromedriver.exe which is prsent in downlod file\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "url='https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job=driver.find_element_by_id('qsb-keyword-sugg')\n",
    "search_job.send_keys(\"data scientist\")\n",
    "search_loc=driver.find_element_by_id('qsb-location-sugg')\n",
    "search_loc.send_keys(\"Delhi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"64f1faf601f5d12c045130ea1b404ce7\", element=\"93753d48-09ea-4595-9222-7e63e5c606a1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"64f1faf601f5d12c045130ea1b404ce7\", element=\"6e774a4f-0752-45a8-88aa-b3015223e558\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"64f1faf601f5d12c045130ea1b404ce7\", element=\"f0d5cb91-4fd6-4cae-a704-0aa6926b2d99\")>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_btn=driver.find_elements_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_element_by_class_name('btn')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"49041d37-a461-490a-a115-7c13f2de2dd7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"0fc0c8e4-1339-420c-a18f-1c67b1c6a9cc\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"82a5e425-204f-45ec-b232-6b56995b4146\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"11e1721b-8bd3-44a1-bf09-ae9ebd31f1d3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"f16e7a1e-f566-4d9b-9acf-0a7a06df677f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"d9722452-a58b-43a7-bd3f-5aec6c8de0bf\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"971deb0e-0d34-49b8-9320-05fe95ab49dc\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"e245dc23-b651-4acf-aacf-c24cb8f419b9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"4ddd6d16-96ea-4f3c-8a8f-d4bf4d7085dd\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"b519dc1c-6064-4a52-aeec-2ff181237768\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"cc7fa5cd-b505-4cea-af71-5b263060ab60\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"74dc5d39-c69b-4121-929e-4de63b678a6e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"5ba43940-c14b-4c46-a7fa-e5e8cf3fec73\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"fc4b9f2d-0f50-4ac0-9a6d-7ca7cec3c51e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"0227d046-1a00-4d85-9d53-1f2e7c53f7b0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"a029763e-9625-4789-a16d-a3df734371bd\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"59a41ea4-4e4c-477a-91cc-b58383d56b6f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"443cd76f-4301-4919-9bd9-0fb38a218f83\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"a3e7f5bf-0d1f-4810-bfab-b8d5489dd848\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"bc01758e-1c88-4670-a222-82b70e5bff4b\")>]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract all the tags havng job title\n",
    "title_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "title_tags                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"49041d37-a461-490a-a115-7c13f2de2dd7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"0fc0c8e4-1339-420c-a18f-1c67b1c6a9cc\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"82a5e425-204f-45ec-b232-6b56995b4146\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"11e1721b-8bd3-44a1-bf09-ae9ebd31f1d3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"f16e7a1e-f566-4d9b-9acf-0a7a06df677f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"d9722452-a58b-43a7-bd3f-5aec6c8de0bf\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"971deb0e-0d34-49b8-9320-05fe95ab49dc\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"e245dc23-b651-4acf-aacf-c24cb8f419b9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"4ddd6d16-96ea-4f3c-8a8f-d4bf4d7085dd\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"b519dc1c-6064-4a52-aeec-2ff181237768\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"cc7fa5cd-b505-4cea-af71-5b263060ab60\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"74dc5d39-c69b-4121-929e-4de63b678a6e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"5ba43940-c14b-4c46-a7fa-e5e8cf3fec73\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"fc4b9f2d-0f50-4ac0-9a6d-7ca7cec3c51e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"0227d046-1a00-4d85-9d53-1f2e7c53f7b0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"a029763e-9625-4789-a16d-a3df734371bd\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"59a41ea4-4e4c-477a-91cc-b58383d56b6f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"443cd76f-4301-4919-9bd9-0fb38a218f83\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"a3e7f5bf-0d1f-4810-bfab-b8d5489dd848\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"bc01758e-1c88-4670-a222-82b70e5bff4b\")>]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior Data Scientist ( m / f / d )',\n",
       " 'Sr Data Scientist',\n",
       " 'Sr. Data Scientist/Data Scientist',\n",
       " 'Co-Founder & Principal Data Scientist/Senior Scientist',\n",
       " 'Data Scientist / Data Analyst',\n",
       " 'Co-Founder - Principal Data Scientist/Senior Data Scientist',\n",
       " 'Senior Data Scientist (m/f/d)',\n",
       " 'Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Data Analyst/Data Scientist',\n",
       " 'Data Scientist : Manager / Sn. Manager / one of the MNC',\n",
       " 'Data Scientist : Manager / Sn. Manager / one of the MNC',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Data Scientist: Advanced Analytics',\n",
       " 'Only Fresher / Data Scientist / Data Analyst / Analytics - MNC Jobs',\n",
       " 'Associate Manager - Data Engineering/Data Modelling/Data Scientist',\n",
       " 'Data Scientist']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract job title is inside the tags using for loop\n",
    "job_titles=[]\n",
    "for i in title_tags:\n",
    "    job_titles.append(i.text)\n",
    "job_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"9f430b1a-5152-43df-9ccb-2543a221280c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"f3dad77f-a87d-409b-afed-94b3d3dd6e58\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"2ff3ca64-1bbc-42d5-8cb2-6a9365b61288\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"6651e34b-0a52-4da1-9d45-e769bc88b86c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"c690bd0f-d3e6-4d0c-bdee-83b0e384d992\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"1c234262-ac32-4928-a9da-5be1ff651410\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"f6ed3921-6cb6-4776-96ea-e03852f03a0d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"f389592e-b6d5-415b-9309-9d38295c5467\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"89610425-8355-475d-9620-31a3bffc6900\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"42d1172d-7e6a-45be-b221-60ed0389e786\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"cb24d1bc-625b-496e-9ef1-bd9d737a3426\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"0110cdd2-3fdf-4ec6-afbf-799535d2e279\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"8fd33bf7-46f2-426c-b553-f3f91095acb1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"13d99f6a-a286-499c-80ca-af7ee644f77a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"857fb545-f407-4fbe-92cc-5336451a65c8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"321acc9a-e549-4f2c-af4d-515de5002282\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"f56bd28f-1c14-4fe7-9c61-3fdcf07fa1e7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"060e30d1-3cd0-4f01-b154-23a1379a7e2e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"c92bd617-2d64-4448-b9a1-8808a6baf9d8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"93e4594f-22e3-42cd-8a36-bcd05670517e\")>]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "company_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adidas Group',\n",
       " 'Superior Group',\n",
       " 'Pentair Water India Pvt Ltd',\n",
       " 'Benovymed Healthcare',\n",
       " 'CARS24',\n",
       " 'Benovymed Healthcare Private Limited',\n",
       " 'Adidas Group',\n",
       " 'Oracle India Pvt. Ltd.',\n",
       " 'Aryng',\n",
       " 'Skillenable Fintech Private Limited',\n",
       " 'Mount Talent Consulting Private Limited',\n",
       " 'Mount Talent Consulting Private Limited',\n",
       " 'PROCESS NINE TECHNOLOGIES PVT.LTD.',\n",
       " 'Lenskart.com',\n",
       " 'Altran Technologies India Private Limited.',\n",
       " 'TalentStack',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'GABA Consultancy services',\n",
       " 'RateGain Travel technologies Pvt. Ltd.',\n",
       " 'R Systems International Ltd.']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract company title is inside the tags using for loop\n",
    "company_titles=[]\n",
    "for i in company_tags:\n",
    "    company_titles.append(i.text)\n",
    "company_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"fc4111ca-0a76-482c-8002-22728c082b90\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"91e37f8e-5141-4ad0-87f6-41405fa128a3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"0ab92672-a806-4eba-8d73-046c3030f636\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"fdf91698-f463-4179-a6f8-f9701eaea10d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"26e5a646-675d-47ed-b37a-e0eba5209310\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"89a8fe4a-158e-4be8-b40b-ba27e7fab173\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"2bc5dad4-41c4-4ea8-a803-4eb9e366e216\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"7c94a021-1bf3-42c3-8930-10be8f2bce62\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"254a5de3-a094-4a1e-a0ec-cb3f7b426096\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"82573d8d-6e05-4707-8654-daf31100c9e9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"c2ea7c52-f98b-46f2-833f-3a674685dd80\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"33e69cb0-58a3-451f-bc5e-7234909d0e8a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"1946f5e2-6552-4a48-ad83-eae805c78495\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"52c2f963-996e-4f5d-aab0-caf5c5f35178\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"2195e2be-40f8-4a3d-be5f-6f6916c2a267\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"831e4f0f-9657-46db-a5a1-cbcffb9c46aa\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"f52314db-bd72-4a8f-b784-97074587c7b5\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"ec82470d-9c24-4a29-9453-db5d0d06c76d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"34dd213d-c293-4303-b17c-5e684522736b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"b18754b1-1cc7-499f-9acb-c1d24bcfbfad\")>]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiance_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span[1]\")\n",
    "experiance_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5-10 Yrs',\n",
       " '6-11 Yrs',\n",
       " '8-12 Yrs',\n",
       " '2-7 Yrs',\n",
       " '1-5 Yrs',\n",
       " '2-7 Yrs',\n",
       " '5-10 Yrs',\n",
       " '5-9 Yrs',\n",
       " '4-9 Yrs',\n",
       " '2-5 Yrs',\n",
       " '8-13 Yrs',\n",
       " '8-13 Yrs',\n",
       " '1-3 Yrs',\n",
       " '3-8 Yrs',\n",
       " '3-8 Yrs',\n",
       " '7-12 Yrs',\n",
       " '5-10 Yrs',\n",
       " '0-0 Yrs',\n",
       " '5-8 Yrs',\n",
       " '3-6 Yrs']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract experiance  is inside the tags using for loop\n",
    "experiance_yr=[]\n",
    "for i in experiance_tags:\n",
    "    experiance_yr.append(i.text)\n",
    "experiance_yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"55a8ecf8-b9b5-459e-a2c6-28b592ec5c38\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"f9fa7177-a8a9-4fa8-92cd-d83abcacefc8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"2d892cf7-0e96-440a-9c41-8e195707632d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"2e815891-045d-4b1c-ac85-f80c37511860\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"21bb473d-3fc1-4790-b70f-056c7d191700\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"83cd0607-fbd4-4371-8abc-c34f36abf004\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"40f39a38-1aee-4664-b195-485dee1b008a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"1728723f-37a1-4b88-9121-5b3716fd9b50\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"b1a6bb88-70d9-4deb-8a70-c1c97971a98c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"b22b6d63-dcb2-4cef-88b3-3e08b1f0fc25\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"636be220-d7bf-4888-ac91-9e6f834c04b6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"fb34fde2-1e1f-42e0-80d4-dff441179409\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"4a3b25ca-a8b0-4739-b9f8-4b4c4e2991c5\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"a4a20c22-7e31-4af7-b7f0-9ecac6b364b3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"023b5483-54c2-4892-80d3-70f586229358\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"956e2c27-5558-4978-9094-37dfbdc1a76f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"b4aad4a3-3895-4ed3-bf8d-6f618de92404\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"938cf46f-0d12-4d24-a433-e45431d5d832\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"b8edd023-f9ff-40eb-b833-a3de58925bb6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"ea7582d1-7c89-4027-a58d-8f33e3cf892b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"556b898e-b2e1-4416-9f3b-5c6d43868268\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"1dea3364-eff1-4b5a-990c-7fb645ae9fa3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"71371fccb7fec6f5e3fb1ac23d3c16cc\", element=\"22f9d041-0437-4c5d-94e4-85714a54b640\")>]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")\n",
    "location_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gurgaon/Gurugram',\n",
       " 'New Delhi',\n",
       " 'Noida',\n",
       " 'Gurgaon/Gurugram, Delhi / NCR',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Gurgaon/Gurugram, Delhi / NCR',\n",
       " 'Gurgaon/Gurugram, United States (USA)',\n",
       " 'Noida, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru, Delhi',\n",
       " 'Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Gurgaon/Gurugram',\n",
       " '(WFH during Covid)',\n",
       " 'Faridabad',\n",
       " 'Gurgaon/Gurugram',\n",
       " '(WFH during Covid)',\n",
       " 'Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Delhi / NCR',\n",
       " 'Noida, Gurgaon/Gurugram, Delhi / NCR',\n",
       " 'Noida',\n",
       " 'Noida',\n",
       " '(WFH during Covid)']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract experiance  is inside the tags using for loop\n",
    "location=[]\n",
    "for i in location_tags:\n",
    "    location.append(i.text)\n",
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "20\n",
      "23\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(job_titles)),print(len(company_titles)),print(len(experiance_yr)),print(len(location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Comp Title</th>\n",
       "      <th>Exp</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist ( m / f / d )</td>\n",
       "      <td>Adidas Group</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>Superior Group</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>New Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sr. Data Scientist/Data Scientist</td>\n",
       "      <td>Pentair Water India Pvt Ltd</td>\n",
       "      <td>8-12 Yrs</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Co-Founder &amp; Principal Data Scientist/Senior S...</td>\n",
       "      <td>Benovymed Healthcare</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist / Data Analyst</td>\n",
       "      <td>CARS24</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Co-Founder - Principal Data Scientist/Senior D...</td>\n",
       "      <td>Benovymed Healthcare Private Limited</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist (m/f/d)</td>\n",
       "      <td>Adidas Group</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram, United States (USA)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Oracle India Pvt. Ltd.</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Aryng</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst/Data Scientist</td>\n",
       "      <td>Skillenable Fintech Private Limited</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                Senior Data Scientist ( m / f / d )   \n",
       "1                                  Sr Data Scientist   \n",
       "2                  Sr. Data Scientist/Data Scientist   \n",
       "3  Co-Founder & Principal Data Scientist/Senior S...   \n",
       "4                      Data Scientist / Data Analyst   \n",
       "5  Co-Founder - Principal Data Scientist/Senior D...   \n",
       "6                      Senior Data Scientist (m/f/d)   \n",
       "7                                     Data Scientist   \n",
       "8                              Senior Data Scientist   \n",
       "9                        Data Analyst/Data Scientist   \n",
       "\n",
       "                             Comp Title       Exp  \\\n",
       "0                          Adidas Group  5-10 Yrs   \n",
       "1                        Superior Group  6-11 Yrs   \n",
       "2           Pentair Water India Pvt Ltd  8-12 Yrs   \n",
       "3                  Benovymed Healthcare   2-7 Yrs   \n",
       "4                                CARS24   1-5 Yrs   \n",
       "5  Benovymed Healthcare Private Limited   2-7 Yrs   \n",
       "6                          Adidas Group  5-10 Yrs   \n",
       "7                Oracle India Pvt. Ltd.   5-9 Yrs   \n",
       "8                                 Aryng   4-9 Yrs   \n",
       "9   Skillenable Fintech Private Limited   2-5 Yrs   \n",
       "\n",
       "                                            Location  \n",
       "0                                   Gurgaon/Gurugram  \n",
       "1                                          New Delhi  \n",
       "2                                              Noida  \n",
       "3                      Gurgaon/Gurugram, Delhi / NCR  \n",
       "4                                   Gurgaon/Gurugram  \n",
       "5                      Gurgaon/Gurugram, Delhi / NCR  \n",
       "6              Gurgaon/Gurugram, United States (USA)  \n",
       "7                         Noida, Bangalore/Bengaluru  \n",
       "8                         Bangalore/Bengaluru, Delhi  \n",
       "9  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs=pd.DataFrame({})\n",
    "jobs['Job Title']=job_titles[:10]\n",
    "jobs['Comp Title']=company_titles[:10]\n",
    "jobs['Exp']=experiance_yr[:10]\n",
    "jobs['Location']=location[:10]\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- 1. All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first connect to the web driver through chromedriver.exe which is prsent in downlod file\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job=driver.find_element_by_id('qsb-keyword-sugg')\n",
    "search_job.send_keys(\"data scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_loc=driver.find_element_by_id('qsb-location-sugg')\n",
    "search_loc.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"e4ce5775cb8aa18b860fad54bed9eeb6\", element=\"268c89fe-0419-47dd-92e8-c647ce392c5a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"e4ce5775cb8aa18b860fad54bed9eeb6\", element=\"7e90dea7-644d-44bf-ba76-a86967c12b54\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"e4ce5775cb8aa18b860fad54bed9eeb6\", element=\"a3397dff-a144-4a24-b343-b08a1e42b056\")>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_btn=driver.find_elements_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_element_by_class_name('btn')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Comp Title</th>\n",
       "      <th>Exp</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lead Data Scientist BFSI</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Airbnb</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SENIOR DATA SCIENTIST</td>\n",
       "      <td>Happiest Minds Technologies Pvt.Ltd</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist (Python &amp; SQL)</td>\n",
       "      <td>AVE-Promagne</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad, Chennai, Bangalore/Ben...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lead Data Scientist - Machine Learning/ Data M...</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Freelance Data Scientist Project Based</td>\n",
       "      <td>Shikvix</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Remote</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                           Lead Data Scientist BFSI   \n",
       "1                           Associate Data Scientist   \n",
       "2                 Data Scientist: Advanced Analytics   \n",
       "3                              Senior Data Scientist   \n",
       "4                              SENIOR DATA SCIENTIST   \n",
       "5                      Data Scientist (Python & SQL)   \n",
       "6                                  Sr Data Scientist   \n",
       "7                                  Sr Data Scientist   \n",
       "8  Lead Data Scientist - Machine Learning/ Data M...   \n",
       "9             Freelance Data Scientist Project Based   \n",
       "\n",
       "                            Comp Title       Exp  \\\n",
       "0               IBM India Pvt. Limited   5-9 Yrs   \n",
       "1                Philips India Limited   3-5 Yrs   \n",
       "2               IBM India Pvt. Limited   3-7 Yrs   \n",
       "3                               Airbnb  7-12 Yrs   \n",
       "4  Happiest Minds Technologies Pvt.Ltd  5-10 Yrs   \n",
       "5                         AVE-Promagne   6-8 Yrs   \n",
       "6               IBM India Pvt. Limited   6-8 Yrs   \n",
       "7               IBM India Pvt. Limited   6-8 Yrs   \n",
       "8         Wrackle Technologies Pvt Ltd  6-11 Yrs   \n",
       "9                              Shikvix   3-8 Yrs   \n",
       "\n",
       "                                            Location  \n",
       "0                                Bengaluru/Bangalore  \n",
       "1                                Bangalore/Bengaluru  \n",
       "2                                Bengaluru/Bangalore  \n",
       "3                                Bangalore/Bengaluru  \n",
       "4                                Bangalore/Bengaluru  \n",
       "5  Hyderabad/Secunderabad, Chennai, Bangalore/Ben...  \n",
       "6                                Bengaluru/Bangalore  \n",
       "7                                Bangalore/Bengaluru  \n",
       "8                                Bangalore/Bengaluru  \n",
       "9                                             Remote  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract all the tags havng job title\n",
    "title_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "#extract job title is inside the tags using for loop\n",
    "job_titles=[]\n",
    "for i in title_tags:\n",
    "    job_titles.append(i.text)\n",
    "\n",
    "company_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "#extract company title is inside the tags using for loop\n",
    "company_titles=[]\n",
    "for i in company_tags:\n",
    "    company_titles.append(i.text)\n",
    "experiance_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span[1]\")\n",
    "#extract experiance  is inside the tags using for loop\n",
    "experiance_yr=[]\n",
    "for i in experiance_tags:\n",
    "    experiance_yr.append(i.text)\n",
    "\n",
    "location_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")\n",
    "#extract experiance  is inside the tags using for loop\n",
    "location=[]\n",
    "for i in location_tags:\n",
    "    location.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "url='https://www.naukri.com/data-scientist-jobs-in-bangalore-bengaluru?k=data%20scientist&l=bangalore%2Fbengaluru'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.naukri.com/job-listings-lead-data-scientist-bfsi-ibm-india-pvt-limited-bengaluru-bangalore-5-to-9-years-070921901691?src=jobsearchDesk&sid=16311116007807007&xp=1&px=1',\n",
       " 'https://www.naukri.com/job-listings-associate-data-scientist-philips-india-limited-bangalore-bengaluru-3-to-5-years-060921501985?src=jobsearchDesk&sid=16311116007807007&xp=2&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-advanced-analytics-ibm-india-pvt-limited-bengaluru-bangalore-3-to-7-years-070921901677?src=jobsearchDesk&sid=16311116007807007&xp=3&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-airbnb-bangalore-bengaluru-7-to-12-years-080921500017?src=jobsearchDesk&sid=16311116007807007&xp=4&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-happiest-minds-technologies-pvt-ltd-bangalore-bengaluru-5-to-10-years-070921501517?src=jobsearchDesk&sid=16311116007807007&xp=5&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-python-sql-ave-promagne-hyderabad-secunderabad-chennai-bangalore-bengaluru-6-to-8-years-060921904967?src=jobsearchDesk&sid=16311116007807007&xp=6&px=1',\n",
       " 'https://www.naukri.com/job-listings-sr-data-scientist-ibm-india-pvt-limited-bengaluru-bangalore-6-to-8-years-010921906637?src=jobsearchDesk&sid=16311116007807007&xp=7&px=1',\n",
       " 'https://www.naukri.com/job-listings-sr-data-scientist-ibm-india-pvt-limited-bangalore-bengaluru-6-to-8-years-010921906105?src=jobsearchDesk&sid=16311116007807007&xp=8&px=1',\n",
       " 'https://www.naukri.com/job-listings-lead-data-scientist-machine-learning-data-mining-wrackle-technologies-pvt-ltd-bangalore-bengaluru-6-to-11-years-080221900886?src=jobsearchDesk&sid=16311116007807007&xp=9&px=1',\n",
       " 'https://www.naukri.com/job-listings-freelance-data-scientist-project-based-shikvix-bangalore-bengaluru-3-to-8-years-060921008814?src=jobsearchDesk&sid=16311116007807007&xp=10&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-neenopal-intelligent-solutions-private-limited-bangalore-bengaluru-2-to-5-years-080921006998?src=jobsearchDesk&sid=16311116007807007&xp=11&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-prescience-decision-solutions-private-limited-bangalore-bengaluru-5-to-10-years-080921005624?src=jobsearchDesk&sid=16311116007807007&xp=12&px=1',\n",
       " 'https://www.naukri.com/job-listings-requirement-for-data-scientist-mumbai-bangalore-crisil-limited-bangalore-bengaluru-mumbai-all-areas-2-to-6-years-080921005523?src=jobsearchDesk&sid=16311116007807007&xp=13&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-elpis-it-solutions-pvt-ltd-bangalore-bengaluru-3-to-8-years-070921602158?src=jobsearchDesk&sid=16311116007807007&xp=14&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-elpis-it-solutions-pvt-ltd-bangalore-bengaluru-3-to-8-years-070921002157?src=jobsearchDesk&sid=16311116007807007&xp=15&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-ml-sp-staffing-services-private-limited-pune-chennai-bangalore-bengaluru-10-to-15-years-100621006203?src=jobsearchDesk&sid=16311116007807007&xp=16&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-oracle-india-pvt-ltd-noida-bangalore-bengaluru-5-to-9-years-010621004567?src=jobsearchDesk&sid=16311116007807007&xp=17&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-ibm-india-pvt-limited-bengaluru-bangalore-2-to-4-years-010921906678?src=jobsearchDesk&sid=16311116007807007&xp=18&px=1',\n",
       " 'https://www.naukri.com/job-listings-cognitive-data-scientist-ibm-india-pvt-limited-bengaluru-bangalore-3-to-7-years-030921904668?src=jobsearchDesk&sid=16311116007807007&xp=19&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-python-big-data-capgemini-technology-services-india-limited-hyderabad-secunderabad-chennai-bangalore-bengaluru-6-to-11-years-030921008208?src=jobsearchDesk&sid=16311116007807007&xp=20&px=1']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "    urls.append(i.get_attribute(\"href\"))\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_desc=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        job=driver.find_element_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "        job_title.append(job.text.replace(\"/n\",\"new line\"))\n",
    "    except:\n",
    "        job_title.append(\"-\")\n",
    "#fetching job description\n",
    "    try:\n",
    "        job_des=driver.find_element_by_xpath(\"//section[@class='job-desc']\")\n",
    "        job_desc.append(job_des.text)\n",
    "    except:\n",
    "        job_desc.append(\"-\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-',\n",
       " 'Associate Data Scientist',\n",
       " '-',\n",
       " 'Senior Data Scientist',\n",
       " 'SENIOR DATA SCIENTIST',\n",
       " 'Data Scientist (Python & SQL)',\n",
       " '-',\n",
       " '-',\n",
       " 'Lead Data Scientist - Machine Learning/ Data Mining',\n",
       " 'Freelance Data Scientist Project Based',\n",
       " '-',\n",
       " 'Associate Data Scientist',\n",
       " '-',\n",
       " 'Senior Data Scientist',\n",
       " 'SENIOR DATA SCIENTIST',\n",
       " 'Data Scientist (Python & SQL)',\n",
       " '-',\n",
       " '-',\n",
       " 'Lead Data Scientist - Machine Learning/ Data Mining',\n",
       " 'Freelance Data Scientist Project Based',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Requirement For Data Scientist - Mumbai & Bangalore',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Senior Data Scientist - ML',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " 'Associate Data Scientist',\n",
       " '-',\n",
       " 'Senior Data Scientist',\n",
       " 'SENIOR DATA SCIENTIST',\n",
       " 'Data Scientist (Python & SQL)',\n",
       " '-',\n",
       " '-',\n",
       " 'Lead Data Scientist - Machine Learning/ Data Mining',\n",
       " 'Freelance Data Scientist Project Based',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Requirement For Data Scientist - Mumbai & Bangalore',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Senior Data Scientist - ML',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " 'Associate Data Scientist',\n",
       " '-',\n",
       " 'Senior Data Scientist',\n",
       " 'SENIOR DATA SCIENTIST',\n",
       " 'Data Scientist (Python & SQL)',\n",
       " '-',\n",
       " '-',\n",
       " 'Lead Data Scientist - Machine Learning/ Data Mining',\n",
       " 'Freelance Data Scientist Project Based',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Requirement For Data Scientist - Mumbai & Bangalore',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Senior Data Scientist - ML',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " 'Job description\\nUse predictive modeling to increase and optimize customer experiences, revenue generation, campaign optimization and other business outcomes\\nWork with product management to develop data use cases and embed predictive models in workflows on resource constrained platforms and cloud enabled.\\nSelecting features, building and optimizing classifiers using machine learning and deep learning techniques\\nCollaborates with Data Engineers to enhance data collection and ingestion/curation techniques to include information that is relevant for building analytic systems\\nProcessing, cleansing, and verifying the integrity of data used for analysis\\nDevelop processes and tools to monitor and analyze model performance and data accuracy. Life cycle management of predictive models.\\nAdherence to compliance procedures in accordance with regulatory standards, requirements, and policies. Managing and designing the reporting environment, including data sources security, and metadata.\\nJob Qualifications:\\nMaster s degree or PhD in Computer Science, Information management, Statistics or related field, with 3 to 5 years of experience in the Consumer or Healthcare industry manipulating data sets and building predictive models with focus on product development\\nExperience in statistical modelling, machine learning, data mining, unstructured data analytics and natural language processing. Sound understanding of - Bayesian Modelling, Classification Models, Cluster Analysis, Neural Network, Nonparametric Methods, Multivariate Statistics, etc.\\nStrong hands on knowledge of ML techniques like regression algorithms, K-NN, Na ve Bayes, SVM and ensemble techniques like Random forest, AdaBoost etc\\nHaving strong knowledge in unsupervised learning algorithms using Neural networks and Deep-Learning\\nStrong knowledge in Data Wrangling and Exploration techniques to identify the patterns, trends and outliners.\\nDeep knowledge and practical experience with data science toolkits, such as NumPy, Pandas, scikit-learn or equivalent\\nExperience with data visualization tools, such as QlikView, Matplotlib, seaborn or equivalent tools.\\nProficiency in using query languages, such as SQL, PL/SQL\\nHands on experience in the one or more databases like Hadoop, AWS Redshift, Snowflake etc.\\nGood applied statistics skills, such as distributions, statistical testing, regression, etc.\\nGood ETL scripting and programming skills, such as Python, R or Scala to integrate developed solution into the proposition.\\nA team player capable of working and integrating across cross-functional team for implementing project requirements. Experience in technical requirements gathering and documentation.\\nAbility to work effectively and independently in a fast-paced global collaborative agile team environment with tight deadlines\\nA flexible, pragmatic and collaborative team player with innate ability to engage with stakeholders at all levels in the organization.\\nA self-starter with high levels of drive, energy, resilience and a desire for professional excellence with a passion for data and data science\\nRoleClinical Research Associate/Scientist\\nIndustry TypeMedical Services / Hospital\\nFunctional AreaMedical, Healthcare, R&D, Pharmaceuticals, Biotechnology\\nEmployment TypeFull Time, Permanent\\nRole CategoryR&D\\nEducation\\nUG :Any Graduate\\nPG :Post Graduation Not Required\\nKey Skills\\nProduct managementComputer sciencemetadataMachine learningAgilePLSQLHealthcareQlikViewData miningPython',\n",
       " '-',\n",
       " 'Job description\\nResponsibilities include:\\nDefining and evaluating key metrics and understanding what moves them and why\\nOwnership of conceptualizing, developing, and maintaining dashboards and visualizations\\nInvestigating evolving fraud trends to extract patterns, identify root causes and propose actionable solutions\\nCommunicating analyses and recommendations to cross functional stakeholders for decision making\\nEmpowering the team to answer data questions quickly and easily by building high-quality ground truth data sets\\nHere are example traits we value:\\nProfessional industry experience in a quantitative analysis role (7+ years preferred)\\nComfortable in SQL and some experience with a programming language (Python or R a plus)\\nAbility to communicate clearly and effectively to cross functional partners of varying technical levels\\nAbility to define relevant metrics that can guide and influence stakeholders to the appropriate and accurate insights\\nExperience or willingness to learn tools to create data pipelines using Airflow\\nBuilding clear and easy to understand dashboards (Tableau) and presentations\\nRoleGraphic/Web Designer\\nIndustry TypeInternet\\nFunctional AreaIT Software - DBA, Datawarehousing\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :Any Graduate\\nPG :Any Postgraduate\\nKey Skills\\nData ScienceRData ScientistTableauPythonSql',\n",
       " 'Job description\\n  Skills\\nRequired Skills: Data Science, Machine Learning, Deep Learning, Python, NLP\\nDesired Skills: Computer Vision\\nRoles and responsibilities\\nExperience in Data Modelling, R, Python, SQL, Data Science, Machine Learning, Deep Learning, NLP, Statistics\\nHave ability to solve Business problems using Data\\nShould possess extensive knowledge of and experience in applying data mining and machine learning techniques on large amount of datasets\\nHigh level of proficiency in statistical tools like R, Python\\nCandidate will be expected to communicate analytical results in a way that is meaningful for business stakeholders and provides actionable insights.\\nHave the ability to discover new opportunities where advanced analytical techniques can be leveraged for solving business problems\\nGood to Have\\nExpertise in programming languages like Java/C/C /Python\\nExperience with relational databases and SQL is good to have\\nExperience in audio and video analytics\\nRelevant experience in Big Data platforms like Hadoop eco-system\\nCome up with innovative algorithms and solutions\\nStaffing Type:Permanent\\nRoleClinical Research Associate/Scientist\\nIndustry TypeIT Services & Consulting\\nFunctional AreaMedical, Healthcare, R&D, Pharmaceuticals, Biotechnology\\nEmployment TypeFull Time, Permanent\\nRole CategoryR&D\\nEducation\\nUG :Any Graduate\\nPG :Any Postgraduate\\nKey Skills\\nHospitalityNSEStaffingBfsiAnalyticalAgileData miningAnalyticsAutomotiveSQL',\n",
       " 'Job description\\nRequired Technical and Professional Expertise\\n• 6+ years of industry work experience in data scientist projects\\n• Master’s degree or higher in Statistics/Math/Computer Science or related field\\n• Background in applied statistical modeling on large experimental or observational data sets\\n• Experience extracting data from a variety of sources, and a desire to expand those skills (working knowledge SQL is required, Spark is a plus)\\n• Experience with one or more statistical or machine learning software such as R, Python, etc.\\n• Must showcase past work through published articles/GitHub/social media\\n\\nPreferred Technical and Professional Expertise\\n• Knowledge of distributed computing systems, e.g. Cosmos, Spark, Hadoop, and relational database management system\\n• PhD. in Statistics is preferred\\n• You love collaborative environments that use agile methodologies to encourage creative design thinking and find innovative ways to develop with cutting edge technologies\\n• Ambitious individual who can work under their own direction towards agreed targets/goals and with creative approach to work\\n• Intuitive individual with an ability to manage change and proven time management\\n• Proven interpersonal skills while contributing to team effort by accomplishing related results as needed\\nRoleData Analyst\\nIndustry TypeIT Services & Consulting\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :B.Sc in Maths, Statistics\\nPG :MS/M.Sc(Science) in Maths, Statistics\\nDoctorate :Doctorate Not Required\\nKey Skills\\nRData scienceData analyticsSQLPython',\n",
       " '-',\n",
       " '-',\n",
       " 'Job description\\nRoles and Responsibilities\\nRequirements :\\n\\n- 6-9 years of strong experience in data mining, machine learning and statistical analysis.\\n\\n- BS/ MS/ PhD in Computer Science, Statistics, Applied Math, or related areas from Premier institutes ( only IITs / IISc / BITS / Top NITs or top US university should apply)\\n\\n- Ability to lead and deliver in a fast-paced start-up environment.\\n\\n- Fluency in tools such as Python/ R/ Matlab etc.\\n\\n- Strong intuition for data and Keen aptitude on large scale data analysis\\n\\n- Excellent written and verbal communication skills.\\n\\n- Ability to collaborate across teams and strong interpersonal skills.\\nRoleData Analyst\\nIndustry TypeIT Services & Consulting\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :B.Sc in Computers, Statistics\\nPG :MS/M.Sc(Science) in Computers, Statistics\\nDoctorate :Ph.D/Doctorate in Statistics, Computers\\nKey Skills\\nData ScienceRData ScientistData MiningStatistical AnalystMachine LearningMATLABPython',\n",
       " \"Job description\\n\\nJob description:\\n\\nSeeking senior data scientists for project-based roles that involve working on various projects.\\n\\nThe candidate must have experience in Python coding language and machine learning. The candidate will be working on a part-time basis and hours will be flexible based on the candidate's availability.\\nOpportunity to grow in a startup setting.\\nWhat you'll need:\\nB.Tech in CS or Statistics with demonstrable experience of over 5 years through publications/deployed solutions/projects.\\nM.Tech or Ph.D. in CS or Statistics with demonstrable experience of over 3 years through publications/deployed solutions/projects.\\nA deep understanding of applied statistical analysis and predictive modeling is desired.\\nThe candidate must have a thorough grasp of the theory and application of broad ML algorithms namely, but not limited to regression, SVM, Tree, Random Forests, Boosting, Neural Network, clustering, forecasting, deep learning, text analysis, etc.\\nIt is not expected that the candidate has actually worked on all these modules.\\nStrong proficiency in Python or R is necessary\\n\\nRoleData Analyst\\nIndustry TypeIT Services & Consulting\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypePart Time, Freelance/Homebased\\nRole CategoryAnalytics & BI\\nEducation\\nUG :Any Graduate\\nKey Skills\\nPredictive ModelingRAlgorithmsSVMClusteringMachine LearningStatistical AnalysisStatisticsDeep LearningPython\",\n",
       " 'Job description\\nRoles and Responsibilities\\nWe are looking for someone who would be responsible for analyzing data and providing business insights. As a Data Scientist your responsibilities will include understanding the business problem and experimenting with different modelling architectures to create the best possible setup from model performance as well as computational performance. To do this job successfully, you need exceptional skills in Machine Learning and Programming. Your ultimate goal will be to find the best data-based solution for the problem at hand.\\nMoreover, you are expected to learn fast and deliver quickly in a fast-paced startup environment. If you thrive on ambiguity and are a problem solver and yet deliver value to clients, feel free to reach out to us.\\nWe are looking ONLY FOR SELF DRIVEN INDIVIDUALS with a desire to excel in Data Science Domain.\\nUnderstanding business objectives and developing models that help to achieve them, along with metrics to track their progress\\nDevelop and maintain robust data processing pipelines and reproducible modeling pipelines\\nBuild mathematical models to solve various problems ranging from Time Series forecasting to Neural Networks and ensure seamless deployment in production pipelines.\\nAnalyze experimental results, iterate and refine models to create significant business impact\\nFollow strict coding standards and other software engineering best practices\\n\\n\\nDesired Candidate Profile\\nProven experience as a Data Scientist or similar role\\nStrong SQL, R/Python Skills\\nShould have familiarity with Machine Learning Models and fundamentals in Forecasting and Optimization Techniques\\nShould have strong mathematical background & analytical bent of mind\\nStrong Problem-Solving Ability\\nAbility to communicate well in a highly collaborative team environment, consisting of both technical and non-technical personnel\\nReliable self-starter that is capable of working with a high degree of autonomy\\n\\n\\nPerks and Benefits\\n\\nNeenOpal is a global management consulting firm with a unique and specialized focus on Data Science.\\nWe provide services across the whole value chain of an organization - Digital Strategy, Sales & Marketing, Supply Chain & Logistics as well as Finance. Youll have a blast doing it in our fun, passionate environment.\\nRoleData scientist\\nIndustry TypeManagement Consulting\\nFunctional AreaIT Software - Other\\nEmployment TypeFull Time, Permanent\\nRole CategoryNot mentioned\\nEducation\\nUG :Any Graduate\\nPG :Any Postgraduate\\nKey Skills\\nData SciencePythonSQL\\nExcelSoftware EngineeringProblem SolvingNeural NetworksTime SeriesData AnalysisBusiness InsightsData ProcessingMachine Learning\\nSkills highlighted with ‘‘ are preferred keyskills',\n",
       " 'Job description\\nHi,\\n\\nWe at Prescience www.prescienceds.com looking for Data Scientist @ Bangalore .\\n\\nRoles and Responsibilities\\nAs a Data Scientist you will be working with senior management of clients to understand the business requirements, define right problem statement and come up with a framework for the solution. You will also work on the solution and at time guide a small team to deliver the same. Part of job role would be develop products in the area of Natural Language Processing, Conversational Interfaces, Text Mining etc.\\n\\nDesired Candidate Profile\\nWhat we are looking for:\\nGood applied statistics skills, such as distributions, statistical testing, regression, etc. Experience in Natural Language Processing, Computer Vision. Exposure to common data science business problems like clustering, classification, anomaly detection, prediction etc.\\nGood understanding of machine learning techniques and algorithms\\nExperience with common data science toolkits Python, R, SAS\\nProficiency in using query languages such as SQL, Hive, etc Experience with NoSQL database, SQL Server, PostgreSQL, MongoDB\\nGreat communication skills\\nData-oriented personality and excellent business analysis skills\\nExperience in solutioning for data science related problems, work with business stakeholders to define right problem statement and solution.\\nOpen to professionals who have data analytics / BI background and then moved to Data Scientist roles.\\n\\nPerks and Benefits\\n\\n\\nRoleOther\\nIndustry TypeIT Services & Consulting\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryOther\\nEducation\\nUG :Any Graduate\\nKey Skills\\nTensorflowPostgreSQLNatural Language ProcessingNeural NetworksMachine LearningStatisticsSQLData ScienceAnomaly DetectionPytorchRNLPMongoDBQlikViewComputer VisionData AnalyticsPython',\n",
       " 'Job description\\n\\nCRISIL (formerly Credit Rating Information Services of India Limited) is an Indian analytical company providing ratings, research, and risk and policy advisory services and is a subsidiary of American company S&P Global\\n\\nWe are looking Data Scientist for Mumbai & Bangalore location\\nCandidates who can join immediately or within 30-45 need only apply\\n\\nPlease refer below JD for your reference-\\n\\nJob Description Data scientist:\\nClient oriented approach to problem solving. Individual should be able to have a holistic view of multiple businesses and develop analytic solutions accordingly.\\nOwn and deliver multiple and complex analytic projects. This would require an understanding of business context, conversion of business problems in modeling, and implementing such solutions to create business value.\\nAlways up to date with the latest use cases of modeling community, machine learning and deep learning algorithms and share knowledge within the team.\\nProficiency in basic statistics, hypothesis testing, segmentation and predictive modeling.\\nAbility to translate and articulate technical thoughts and ideas to a larger audience including influencing skills with peers and senior management.\\nStrong project management skills.\\nAbility to coach and mentor juniors.\\nEagerness to work on new and challenging tasks on a regular basis with an ability to research new ways of doing things better/efficiently.\\nContribute to organizational initiatives in wide ranging areas including competency development, training, organizational building activities etc.\\nSkills\\n\\nBasic Qualifications\\n\\nBachelors Degree with 2+ years of experience in data analytics,\\nHands-on experience in Python / SAS or R programing along with strong experience in SQL and Excel Macros.\\nExperienced in working with large and multiple datasets, data warehouses and ability to pull data using relevant programs and coding.\\nWell versed with necessary data preprocessing and feature engineering skills.\\nAt least 2 years of experience implementing Machine learning algorithms such as Random Forest and Gradient Boosting in solving business problems such as Default classification and macroeconomic forecasting.\\nAt least 1 year of experience implementing deep learning techniques like neural networks\\nExposure to deep learning packages like Tensorflow\\nStrong background in Statistical Analysis\\nBackground in BFSI space will be preferred\\n\\nRoleData Analyst\\nIndustry TypeBanking\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :Any Graduate\\nPG :Any Postgraduate\\nKey Skills\\nrMachine LearningPython\\nTensorflowPredictive ModelingSegmentationNeural NetworksDeep LearningRandom ForestSQL\\nSkills highlighted with ‘‘ are preferred keyskills',\n",
       " 'Job description\\nRoles and Responsibilities\\nJob Description:\\nDevelop data powered insights deriving from distributed, real time streaming applications, and develop AI systems leveraging on such data powered insights.\\nLooking for candidates with passion and energy to work in a high energy team with entrepreneurial culture: Self starter attitude, quick learning aptitude, passion and willingness to deliver on time with quality.\\n\\nJob Skills Required:\\nExpert data science skills using supervised and unsupervised learning. Deep learning.\\nCompute: Spark/Storm/NiFi/Flink/Redis, or other.\\nVisualization: Banana UI, Kibana, or other,\\nTools: H2O, TensorFlow, Mlib, Scikit, Keras or other.\\nMessaging: Kafka, RabbitMQ, or other.\\n\\nStrong Analytical and Math/Statistics skills.\\n\\nQualification :\\nM.Tech/M.E./M.S. in Computer Science, Engineering or a related field, preferably with a concentration, major or minor in Data Science or Machine Learning. PhD would be added advantage.\\n\\nDesired Candidate Profile\\nDesirable s that would strengthen candidacy:\\n Proven track record from public competitions such as from Kagel, Analytics Vidya, etc. \\n\\nExpertise in one or more high level programming languages such as Java, Scala, Python, Go, Erlang, etc.\\n\\nExpertise in developing scalable applications in a distributed environment.\\n\\nStrong SQL or NoSQL skills with one or more open source DBMS such as MySql, MongoDB, Cassandra.\\n\\nExpertise in containerized environments on private or public clouds - Aws Azure, etc.\\n\\n\\nRoleSoftware Developer\\nIndustry TypeIT Services & Consulting\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Temporary/Contractual\\nRole CategoryProgramming & Design\\nEducation\\nUG :Any Graduate\\nPG :Any Postgraduate\\nKey Skills\\ndeep learningKibanatensorflowdata scienceKafkakerasSparkMachine Learning',\n",
       " 'Job description\\nRoles and Responsibilities\\nJob Description:\\nDevelop data powered insights deriving from distributed, real time streaming applications, and develop AI systems leveraging on such data powered insights.\\nLooking for candidates with passion and energy to work in a high energy team with entrepreneurial culture: Self starter attitude, quick learning aptitude, passion and willingness to deliver on time with quality.\\n\\nJob Skills Required:\\nExpert data science skills using supervised and unsupervised learning. Deep learning.\\nCompute: Spark/Storm/NiFi/Flink/Redis, or other.\\nVisualization: Banana UI, Kibana, or other,\\nTools: H2O, TensorFlow, Mlib, Scikit, Keras or other.\\nMessaging: Kafka, RabbitMQ, or other.\\n\\nStrong Analytical and Math/Statistics skills.\\n\\nQualification :\\nM.Tech/M.E./M.S. in Computer Science, Engineering or a related field, preferably with a concentration, major or minor in Data Science or Machine Learning. PhD would be added advantage.\\n\\nDesired Candidate Profile\\nDesirable s that would strengthen candidacy:\\n Proven track record from public competitions such as from Kagel, Analytics Vidya, etc. \\n\\nExpertise in one or more high level programming languages such as Java, Scala, Python, Go, Erlang, etc.\\n\\nExpertise in developing scalable applications in a distributed environment.\\n\\nStrong SQL or NoSQL skills with one or more open source DBMS such as MySql, MongoDB, Cassandra.\\n\\nExpertise in containerized environments on private or public clouds - Aws Azure, etc.\\n\\n\\nRoleSoftware Developer\\nIndustry TypeIT Services & Consulting\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Temporary/Contractual\\nRole CategoryProgramming & Design\\nEducation\\nUG :Any Graduate\\nPG :Any Postgraduate\\nKey Skills\\ndeep learningKibanatensorflowdata scienceKafkakerasSparkMachine Learning',\n",
       " 'Job description\\nDear Candidate,\\n\\nWarm greetings from SP Staffing Services.\\n\\nWe are hiring Data Science / ML Resources for our Client.\\n\\nRole: Sr. Data Scientist - Machine Learning\\nExp: 10 to 15 yrs\\nLocation: Pune, Bangalore, Chennai\\n\\nRequisite:\\n\\nIdeal Resource should have 10+ years of experience in Data Science Machine Learning.\\n\\nResponsibilities:\\n\\nDesign and Develop ML / NLP models for the project requirement\\nDeliver ownership to setup ML / NLP models with respect to tools, data and infrastructure as required\\nWork closely with Product Owner and Product architect right from ML based solution conceptualization till implementation in response to a client requirement\\nThought leadership on building ML/NLP based solution based on client requirements\\nLead the ML / NLP dialogue during the customer visits and other partner events\\n\\nRequired Skills:\\n\\nStrong knowledge of Machine Learning / NLP algorithms Information extraction, named entity recognition, text clustering, Knowledge Graph, text summarization, intent classification, word embeddings, vector space models\\nStrong experience in NLP using Python\\nExperience in developing Microservices and web services\\nUnderstanding of data and data analysis, manage Large Data Sets\\nSound exposure on Pandas, Scikit and Numpy\\nMin 4+ years of experience implementing and deploying machine learning and deep learning frameworks (Spark, TensorFlow, Keras, Caffe, etc.)\\nApplication programming in cloud platforms including Azure, IBM, AWS and GCP\\nHands on experience Data Science / Big Data technology and architecture\\n\\n\\nRoleSoftware Developer\\nIndustry TypeIT Services & Consulting\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :B.Tech/B.E. in Computers\\nKey Skills\\nMachine LearningData SciencePython\\nTensorflowDeep LearningNumpyMicroservicesNLPGCPPandasInformation ExtractionData AnalysisKerasCaffeScikit\\nSkills highlighted with ‘‘ are preferred keyskills',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Comp Title</th>\n",
       "      <th>Exp</th>\n",
       "      <th>Location</th>\n",
       "      <th>job_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lead Data Scientist BFSI</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Airbnb</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SENIOR DATA SCIENTIST</td>\n",
       "      <td>Happiest Minds Technologies Pvt.Ltd</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist (Python &amp; SQL)</td>\n",
       "      <td>AVE-Promagne</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad, Chennai, Bangalore/Ben...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lead Data Scientist - Machine Learning/ Data M...</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Freelance Data Scientist Project Based</td>\n",
       "      <td>Shikvix</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Remote</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                           Lead Data Scientist BFSI   \n",
       "1                           Associate Data Scientist   \n",
       "2                 Data Scientist: Advanced Analytics   \n",
       "3                              Senior Data Scientist   \n",
       "4                              SENIOR DATA SCIENTIST   \n",
       "5                      Data Scientist (Python & SQL)   \n",
       "6                                  Sr Data Scientist   \n",
       "7                                  Sr Data Scientist   \n",
       "8  Lead Data Scientist - Machine Learning/ Data M...   \n",
       "9             Freelance Data Scientist Project Based   \n",
       "\n",
       "                            Comp Title       Exp  \\\n",
       "0               IBM India Pvt. Limited   5-9 Yrs   \n",
       "1                Philips India Limited   3-5 Yrs   \n",
       "2               IBM India Pvt. Limited   3-7 Yrs   \n",
       "3                               Airbnb  7-12 Yrs   \n",
       "4  Happiest Minds Technologies Pvt.Ltd  5-10 Yrs   \n",
       "5                         AVE-Promagne   6-8 Yrs   \n",
       "6               IBM India Pvt. Limited   6-8 Yrs   \n",
       "7               IBM India Pvt. Limited   6-8 Yrs   \n",
       "8         Wrackle Technologies Pvt Ltd  6-11 Yrs   \n",
       "9                              Shikvix   3-8 Yrs   \n",
       "\n",
       "                                            Location job_desc  \n",
       "0                                Bengaluru/Bangalore        -  \n",
       "1                                Bangalore/Bengaluru        -  \n",
       "2                                Bengaluru/Bangalore        -  \n",
       "3                                Bangalore/Bengaluru        -  \n",
       "4                                Bangalore/Bengaluru        -  \n",
       "5  Hyderabad/Secunderabad, Chennai, Bangalore/Ben...        -  \n",
       "6                                Bengaluru/Bangalore        -  \n",
       "7                                Bangalore/Bengaluru        -  \n",
       "8                                Bangalore/Bengaluru        -  \n",
       "9                                             Remote        -  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs=pd.DataFrame({})\n",
    "jobs['Job Title']=job_titles[:10]\n",
    "jobs['Comp Title']=company_titles[:10]\n",
    "jobs['Exp']=experiance_yr[:10]\n",
    "jobs['Location']=location[:10]\n",
    "jobs['job_desc']=job_desc[:10]  \n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.get(\"https://www.naukri.com/data-scientist-jobs?k=data%20scientist\")\n",
    "filter_button=driver.find_elements_by_xpath(\"//p[@class='grey-text lH20 fleft ml-8 txtLbl']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Delhi / NCR':\n",
    "        i.click()\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_button=driver.find_elements_by_xpath(\"//p[@class='grey-text lH20 fleft ml-8 txtLbl']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='3-6 Lakhs':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Comp Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Exp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Job Title, Comp Title, Location, Exp]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract all the tags havng job title\n",
    "title_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "#extract job title is inside the tags using for loop\n",
    "job_titles=[]\n",
    "for i in title_tags:\n",
    "    job_titles.append(i.text)\n",
    "\n",
    "location_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")\n",
    "#extract experiance  is inside the tags using for loop\n",
    "location=[]\n",
    "for i in location_tags:\n",
    "    location.append(i.text)\n",
    "\n",
    "company_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "#extract company title is inside the tags using for loop\n",
    "company_titles=[]\n",
    "for i in company_tags:\n",
    "    company_titles.append(i.text)\n",
    "\n",
    "exp=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "#extract company title is inside the tags using for loop\n",
    "experiance=[]\n",
    "for i in exp:\n",
    "    experiance.append(i.text)\n",
    "\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['Job Title']=job_titles[:10]\n",
    "jobs['Comp Title']=company_titles[:10]\n",
    "jobs['Location']=location[:10]\n",
    "jobs['Exp']=experiance[:10]\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.get(\"https://www.glassdoor.co.in/Job/noida-data-scientist-jobs-SRCH_IL.0,5_IC4477468_KO6,20.htm\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Comp Title</th>\n",
       "      <th>Days Old Post</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Lenskart</td>\n",
       "      <td>1d</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Liberin Technologies Private Limited</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>AlgoScale Technologies Private Limited</td>\n",
       "      <td>14d</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Ishatva Management Solutions</td>\n",
       "      <td>9d</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>limeroad.com</td>\n",
       "      <td>14d</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Science Training Head-Full Time</td>\n",
       "      <td>Emerging India Analytics</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Saishaa Services</td>\n",
       "      <td>16d</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Management Trainee – Data Science</td>\n",
       "      <td>Grail Insights</td>\n",
       "      <td>24h</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Science Consultant</td>\n",
       "      <td>Badatya Private Limited</td>\n",
       "      <td>11d</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Newgen Software</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Job Title  \\\n",
       "0                        Data Scientist   \n",
       "1              Associate Data Scientist   \n",
       "2                        Data Scientist   \n",
       "3                        Data Scientist   \n",
       "4                        Data Scientist   \n",
       "5  Data Science Training Head-Full Time   \n",
       "6                        Data Scientist   \n",
       "7     Management Trainee – Data Science   \n",
       "8               Data Science Consultant   \n",
       "9                        Data Scientist   \n",
       "\n",
       "                               Comp Title Days Old Post Rating  \n",
       "0                                Lenskart            1d    3.6  \n",
       "1    Liberin Technologies Private Limited          30d+    3.5  \n",
       "2  AlgoScale Technologies Private Limited           14d    4.5  \n",
       "3            Ishatva Management Solutions            9d    3.3  \n",
       "4                            limeroad.com           14d    4.2  \n",
       "5                Emerging India Analytics          30d+    3.5  \n",
       "6                        Saishaa Services           16d    3.2  \n",
       "7                          Grail Insights           24h    4.0  \n",
       "8                 Badatya Private Limited           11d    3.8  \n",
       "9                         Newgen Software          30d+    3.8  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract all the tags havng job title\n",
    "title_tags=driver.find_elements_by_xpath(\"//a[@class='jobLink job-search-key-1rd3saf eigr9kq1']/span\")\n",
    "#extract job title is inside the tags using for loop\n",
    "job_titles=[]\n",
    "for i in title_tags:\n",
    "    job_titles.append(i.text)\n",
    "\n",
    "company_tags=driver.find_elements_by_xpath(\"//a[@class=' job-search-key-l2wjgv e1n63ojh0 jobLink']/span\")\n",
    "#extract company title is inside the tags using for loop\n",
    "company_titles=[]\n",
    "for i in company_tags:\n",
    "    company_titles.append(i.text)\n",
    "company_titles\n",
    "\n",
    "days=driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-17n8uzw']\")\n",
    "#extract experiance  is inside the tags using for loop\n",
    "daysold=[]\n",
    "for i in days:\n",
    "    daysold.append(i.text)\n",
    "\n",
    "rating=driver.find_elements_by_xpath(\"//span[@class=' job-search-key-srfzj0 e1cjmv6j0']\")\n",
    "#extract company title is inside the tags using for loop\n",
    "rating_1=[]\n",
    "for i in rating:\n",
    "    rating_1.append(i.text)\n",
    "\n",
    "\n",
    "\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['Job Title']=job_titles[:10]\n",
    "jobs['Comp Title']=company_titles[:10]\n",
    "jobs['Days Old Post']=daysold[:10]\n",
    "jobs['Rating']=rating_1[:10]\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "2. Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "3. Click the search button.\n",
    "4. After that you will land on the below page\n",
    "You have to scrape whole data from this webpage\n",
    "5. Scrape data for first 10 companies. Scrape the min salary, max salary, company name, Average salary and rating of the company.\n",
    "6.Store the data in a dataframe.\n",
    "Note that all of the above steps have to be done by coding only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.get(\"https://www.glassdoor.co.in/Salaries/new-delhi-data-scientist-salary-SRCH_IL.0,9_IM1083_KO10,24.htm?clickSource=searchBtn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comp Title</th>\n",
       "      <th>Number of Salary</th>\n",
       "      <th>Avg salary</th>\n",
       "      <th>MinMax_salary</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>21 salaries</td>\n",
       "      <td>₹6,31,184</td>\n",
       "      <td>Range: ₹4L - ₹13L</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IBM</td>\n",
       "      <td>20 salaries</td>\n",
       "      <td>₹9,08,246</td>\n",
       "      <td>Range: ₹1L - ₹28L</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>15 salaries</td>\n",
       "      <td>₹11,93,390</td>\n",
       "      <td>Range: ₹6L - ₹23L</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>15 salaries</td>\n",
       "      <td>₹12,49,716</td>\n",
       "      <td>Range: ₹5L - ₹1Cr</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹7,58,335</td>\n",
       "      <td>Range: ₹4L - ₹17L</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹12,80,000</td>\n",
       "      <td>Range: ₹8L - ₹16L</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Optum</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>₹13,55,086</td>\n",
       "      <td>Range: ₹8L - ₹20L</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>₹14,55,430</td>\n",
       "      <td>Range: ₹10L - ₹18L</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>₹8,86,064</td>\n",
       "      <td>Range: ₹5L - ₹15L</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>₹11,10,000</td>\n",
       "      <td>Range: ₹6L - ₹16L</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Comp Title Number of Salary  Avg salary       MinMax_salary  \\\n",
       "0  Tata Consultancy Services      21 salaries   ₹6,31,184   Range: ₹4L - ₹13L   \n",
       "1                        IBM      20 salaries   ₹9,08,246   Range: ₹1L - ₹28L   \n",
       "2                  Accenture      15 salaries  ₹11,93,390   Range: ₹6L - ₹23L   \n",
       "3                  Delhivery      15 salaries  ₹12,49,716   Range: ₹5L - ₹1Cr   \n",
       "4         Ericsson-Worldwide      14 salaries   ₹7,58,335   Range: ₹4L - ₹17L   \n",
       "5         UnitedHealth Group      14 salaries  ₹12,80,000   Range: ₹8L - ₹16L   \n",
       "6                      Optum      10 salaries  ₹13,55,086   Range: ₹8L - ₹20L   \n",
       "7     Optum Global Solutions      10 salaries  ₹14,55,430  Range: ₹10L - ₹18L   \n",
       "8         Valiance Solutions      10 salaries   ₹8,86,064   Range: ₹5L - ₹15L   \n",
       "9                EXL Service       9 salaries  ₹11,10,000   Range: ₹6L - ₹16L   \n",
       "\n",
       "  Rating  \n",
       "0    3.9  \n",
       "1    3.9  \n",
       "2    4.1  \n",
       "3    3.8  \n",
       "4      4  \n",
       "5    3.7  \n",
       "6    3.7  \n",
       "7    3.9  \n",
       "8    4.2  \n",
       "9    3.6  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract all the tags havng company title\n",
    "company_tags=driver.find_elements_by_xpath(\"//a[@class='css-f3vw95 e1aj7ssy3']\")\n",
    "#extract company title is inside the tags using for loop\n",
    "company_titles=[]\n",
    "for i in company_tags:\n",
    "    company_titles.append(i.text)\n",
    "\n",
    "\n",
    "avg_salary=driver.find_elements_by_xpath(\"//div[@class='col-12 col-lg-4 px-lg-0 d-flex align-items-baseline']/h3\")\n",
    "\n",
    "Avg_salary=[]\n",
    "for i in avg_salary:\n",
    "    Avg_salary.append(i.text)\n",
    "\n",
    "number_salary=driver.find_elements_by_xpath(\"//div[@class='col-12 col-lg-auto']/span\")\n",
    "\n",
    "Number_salary=[]\n",
    "for i in number_salary:\n",
    "    Number_salary.append(i.text)\n",
    "\n",
    "Number_salary\n",
    "\n",
    "\n",
    "\n",
    "rating=driver.find_elements_by_xpath(\"//span[@class='m-0 css-kyx745']\")\n",
    "\n",
    "Rating=[]\n",
    "for i in rating:\n",
    "    Rating.append(i.text)\n",
    "\n",
    "\n",
    "minmax_salary=driver.find_elements_by_xpath(\"//span[@class='d-block d-lg-none m-0 css-1b6bxoo']\")\n",
    "\n",
    "MinMax_salary=[]\n",
    "for i in minmax_salary:\n",
    "    MinMax_salary.append(i.text)\n",
    "\n",
    "    \n",
    "jobs=pd.DataFrame({})\n",
    "\n",
    "jobs['Comp Title']=company_titles[:10]\n",
    "jobs['Number of Salary']=Number_salary[:10]\n",
    "jobs['Avg salary']=Avg_salary[:10]\n",
    "jobs['MinMax_salary']=MinMax_salary[:10]\n",
    "jobs['Rating']=Rating[:10]\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first connect to the web driver through chromedriver.exe which is prsent in downlod file\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "url='https://www.flipkart.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job=driver.find_element_by_class_name('_3704LK')\n",
    "search_job.send_keys(\"sunglass\")\n",
    "search_btn=driver.find_elements_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search_btn=driver.find_element_by_class_name('L0Z3Pu')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Prod Desc</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LIZA ANGEL</td>\n",
       "      <td>UV Protection, Gradient Wayfarer, Clubmaster S...</td>\n",
       "      <td>₹449</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Rectangular...</td>\n",
       "      <td>₹525</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹198</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹225</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹295</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection Clubmaster Sunglasses (Free Size)</td>\n",
       "      <td>₹398</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>povty</td>\n",
       "      <td>UV Protection Retro Square, Aviator Sunglasses...</td>\n",
       "      <td>₹349</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>UV Protection, Gradient Retro Square Sunglasse...</td>\n",
       "      <td>₹319</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection, Gradient Wayfarer Sunglasses (55)</td>\n",
       "      <td>₹312</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Sports Sunglasses (Free Size)</td>\n",
       "      <td>₹404</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand Name                                          Prod Desc  \\\n",
       "0          LIZA ANGEL  UV Protection, Gradient Wayfarer, Clubmaster S...   \n",
       "1              AISLIN  UV Protection, Polarized, Mirrored Rectangular...   \n",
       "2   SHAAH COLLECTIONS              UV Protection Aviator Sunglasses (54)   \n",
       "3              PIRASO                UV Protection Round Sunglasses (54)   \n",
       "4           Elligator  Mirrored, UV Protection Wayfarer Sunglasses (F...   \n",
       "..                ...                                                ...   \n",
       "95              NuVew    UV Protection Clubmaster Sunglasses (Free Size)   \n",
       "96              povty  UV Protection Retro Square, Aviator Sunglasses...   \n",
       "97         PHENOMENAL  UV Protection, Gradient Retro Square Sunglasse...   \n",
       "98          Elligator   UV Protection, Gradient Wayfarer Sunglasses (55)   \n",
       "99     ROZZETTA CRAFT        UV Protection Sports Sunglasses (Free Size)   \n",
       "\n",
       "   Price Discount  \n",
       "0   ₹449  65% off  \n",
       "1   ₹525  65% off  \n",
       "2   ₹198  88% off  \n",
       "3   ₹225  85% off  \n",
       "4   ₹295  88% off  \n",
       "..   ...      ...  \n",
       "95  ₹398  76% off  \n",
       "96  ₹349  65% off  \n",
       "97  ₹319  84% off  \n",
       "98  ₹312  84% off  \n",
       "99  ₹404  79% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = 1\n",
    "Discount=[]\n",
    "Brnd_Name=[]\n",
    "Prod_desc=[]\n",
    "Price=[]\n",
    "while (counter <=4):\n",
    "    brand_name=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    for i in brand_name:\n",
    "        Brnd_Name.append(i.text)\n",
    "\n",
    "    prod_desc=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    for i in prod_desc:\n",
    "        Prod_desc.append(i.text)    \n",
    "    \n",
    "    price=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    for i in price:\n",
    "        Price.append(i.text)\n",
    "    \n",
    "    discount=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']/span\")\n",
    "    for i in discount:\n",
    "        Discount.append(i.text) \n",
    "        \n",
    "    if (counter>100):\n",
    "            break\n",
    "    else:\n",
    "            counter += 1        \n",
    "            data.append([company,desc,price,discount])\n",
    "            \n",
    "    page_count += 1\n",
    "    driver.find_elements(By.XPATH,\"//nav[@class='yFHi8N']/a\")[-1].click()\n",
    "    time.sleep(2)\n",
    "\n",
    "sunglass=pd.DataFrame({})\n",
    "sunglass['Brand Name']=Brnd_Name[:100]\n",
    "sunglass['Prod Desc']=Prod_desc[:100]\n",
    "sunglass['Price']=Price[:100]\n",
    "sunglass['Discount']=Discount[:100]\n",
    "sunglass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.\n",
    "When you will open the above link you will reach to the below shown webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "url=\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART\"\n",
    "driver.get(url)\n",
    "# Creating empty list\n",
    "urls=[]\n",
    "short_review=[]\n",
    "complete_review=[]\n",
    "stars=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking 10 pages into consideration using for loop\n",
    "url=driver.find_elements_by_xpath(\"//a[@class='ge-49M']\")\n",
    "for i in url:\n",
    "    urls.append(i.get_attribute('href'))\n",
    "    \n",
    "    \n",
    "for j in urls:\n",
    "    driver.get(j)\n",
    "    \n",
    "    #for scrapping the number of stars\n",
    "    \n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\"):\n",
    "        stars.append(j.text)\n",
    "    #for scrapping the short review\n",
    "    \n",
    "    for k in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
    "        short_review.append(k.text)\n",
    "    #for scrapping the complete review   \n",
    "  \n",
    "    for l in driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']/div/div\"):\n",
    "        complete_review.append(l.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money❤️❤️\\nIts awesome mobile phone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Totally in love with this ❤ the camera quality...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>It's my first time to use iOS phone and I am l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Thanks Flipkart For this amazing deal! I had a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>5</td>\n",
       "      <td>Pretty good</td>\n",
       "      <td>I've used this phone for over a month now and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Nice value for money good and best price I pho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Super and marvellous phone look very cute and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Undoubtedly Iphone 11 is the most successful m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating      Review_summary  \\\n",
       "0       5  Highly recommended   \n",
       "1       5    Perfect product!   \n",
       "2       5    Perfect product!   \n",
       "3       5      Classy product   \n",
       "4       5  Highly recommended   \n",
       "..    ...                 ...   \n",
       "75      5  Highly recommended   \n",
       "76      5         Pretty good   \n",
       "77      5           Wonderful   \n",
       "78      5           Wonderful   \n",
       "79      5   Worth every penny   \n",
       "\n",
       "                                          Full Review  \n",
       "0   What a camera .....just awesome ..you can feel...  \n",
       "1   It’s a must buy who is looking for an upgrade ...  \n",
       "2   Value for money❤️❤️\\nIts awesome mobile phone ...  \n",
       "3   Totally in love with this ❤ the camera quality...  \n",
       "4   It's my first time to use iOS phone and I am l...  \n",
       "..                                                ...  \n",
       "75  Thanks Flipkart For this amazing deal! I had a...  \n",
       "76  I've used this phone for over a month now and ...  \n",
       "77  Nice value for money good and best price I pho...  \n",
       "78  Super and marvellous phone look very cute and ...  \n",
       "79  Undoubtedly Iphone 11 is the most successful m...  \n",
       "\n",
       "[80 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "phone_detail=pd.DataFrame({})\n",
    "phone_detail['Rating']=stars[0:80]\n",
    "phone_detail['Review_summary']=short_review[0:80]\n",
    "phone_detail['Full Review']=complete_review[0:80]\n",
    "phone_detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first connect to the web driver through chromedriver.exe which is prsent in downlod file\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "url='https://www.flipkart.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job=driver.find_element_by_class_name('_3704LK')\n",
    "search_job.send_keys(\"sneakers\")\n",
    "search_btn=driver.find_elements_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search_btn=driver.find_element_by_class_name('L0Z3Pu')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Prod Desc</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPARX</td>\n",
       "      <td>Casual Sneakers Sneakers For Men</td>\n",
       "      <td>₹935</td>\n",
       "      <td>23% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>C-Skate Vulc Sneakers For Men</td>\n",
       "      <td>₹2,250</td>\n",
       "      <td>49% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SPARX</td>\n",
       "      <td>SD-323 Sneakers For Men</td>\n",
       "      <td>₹576</td>\n",
       "      <td>23% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Absolutee shoes</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹487</td>\n",
       "      <td>51% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>303 Sneakers For Men</td>\n",
       "      <td>₹299</td>\n",
       "      <td>40% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>VORII</td>\n",
       "      <td>Casual shoes for men white colour syenthetic f...</td>\n",
       "      <td>₹379</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Carlo Style</td>\n",
       "      <td>Casual Sneakers Sneakers For Men</td>\n",
       "      <td>₹380</td>\n",
       "      <td>61% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>C-Skate Vulc Sneakers For Men</td>\n",
       "      <td>₹1,537</td>\n",
       "      <td>53% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>RODDICK SHOES</td>\n",
       "      <td>SD-323 Sneakers For Men</td>\n",
       "      <td>₹474</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>tigonis</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹360</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand Name                                          Prod Desc  \\\n",
       "0                 SPARX                   Casual Sneakers Sneakers For Men   \n",
       "1                  PUMA                      C-Skate Vulc Sneakers For Men   \n",
       "2                 SPARX                            SD-323 Sneakers For Men   \n",
       "3       Absolutee shoes                                   Sneakers For Men   \n",
       "4   World Wear Footwear                               303 Sneakers For Men   \n",
       "..                  ...                                                ...   \n",
       "95                VORII  Casual shoes for men white colour syenthetic f...   \n",
       "96          Carlo Style                   Casual Sneakers Sneakers For Men   \n",
       "97                 PUMA                      C-Skate Vulc Sneakers For Men   \n",
       "98        RODDICK SHOES                            SD-323 Sneakers For Men   \n",
       "99              tigonis                                   Sneakers For Men   \n",
       "\n",
       "     Price Discount  \n",
       "0     ₹935  23% off  \n",
       "1   ₹2,250  49% off  \n",
       "2     ₹576  23% off  \n",
       "3     ₹487  51% off  \n",
       "4     ₹299  40% off  \n",
       "..     ...      ...  \n",
       "95    ₹379  62% off  \n",
       "96    ₹380  61% off  \n",
       "97  ₹1,537  53% off  \n",
       "98    ₹474  52% off  \n",
       "99    ₹360  79% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = 1\n",
    "Discount=[]\n",
    "Brnd_Name=[]\n",
    "Prod_desc=[]\n",
    "Price=[]\n",
    "while (counter <=4):\n",
    "    brand_name=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    for i in brand_name:\n",
    "        Brnd_Name.append(i.text)\n",
    "\n",
    "    prod_desc=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    for i in prod_desc:\n",
    "        Prod_desc.append(i.text)    \n",
    "    \n",
    "    price=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    for i in price:\n",
    "        Price.append(i.text)\n",
    "    \n",
    "    discount=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']/span\")\n",
    "    for i in discount:\n",
    "        Discount.append(i.text) \n",
    "        \n",
    "    if (counter>4):\n",
    "            break\n",
    "    else:\n",
    "            counter += 1        \n",
    "            data.append([company,desc,price,discount])\n",
    "            \n",
    "    page_count += 1\n",
    "    driver.find_elements(By.XPATH,\"//nav[@class='yFHi8N']/a\")[-1].click()\n",
    "    time.sleep(2)\n",
    "\n",
    "sneakers=pd.DataFrame({})\n",
    "sneakers['Brand Name']=Brnd_Name[:100]\n",
    "sneakers['Prod Desc']=Prod_desc[:100]\n",
    "sneakers['Price']=Price[:100]\n",
    "sneakers['Discount']=Discount[:100]\n",
    "sneakers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9: Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, as shown in the below image\n",
    "\n",
    "      \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.get(\"https://www.myntra.com/shoes?f=Color%3ABlack_36454f&plaEnabled=false&rf=Price%3A6871.0_13578.0_6871.0%20TO%2013578.0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_button=driver.find_elements_by_xpath(\"//label[@class='common-customCheckbox vertical-filters-label']//label[@class='price-input']\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Rs. 6871 to Rs. 13578':\n",
    "        i.click()\n",
    "        break\n",
    "filter_button=driver.find_elements_by_xpath(\"//span[@class='colour-label colour-colorDisplay']\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Black':\n",
    "        i.click()\n",
    "        break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Driving Shoes</td>\n",
       "      <td>Rs. 11999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Cell Fraction Fade Running</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Solid Leather Formal Slip-Ons</td>\n",
       "      <td>Rs. 8099Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Printed Slip-On Sneakers</td>\n",
       "      <td>(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men BlackTraining or Gym Shoes</td>\n",
       "      <td>Rs. 10999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Women Solid Leather Gladiators</td>\n",
       "      <td>Rs. 8999Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Women Woven Design Sneakers</td>\n",
       "      <td>(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>RARE RABBIT</td>\n",
       "      <td>Men Leather Flat Boots</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men Textured Leather Formal Loafers</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>PUMA Motorsport</td>\n",
       "      <td>Women BMW M Motorsport Shoes</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Brand                          Description  \\\n",
       "0                   ALDO                    Men Driving Shoes   \n",
       "1                   Puma       Men Cell Fraction Fade Running   \n",
       "2           Hush Puppies    Men Solid Leather Formal Slip-Ons   \n",
       "3                   Geox         Men Printed Slip-On Sneakers   \n",
       "4                   Puma       Men BlackTraining or Gym Shoes   \n",
       "..                   ...                                  ...   \n",
       "95  Heel & Buckle London       Women Solid Leather Gladiators   \n",
       "96                  ALDO          Women Woven Design Sneakers   \n",
       "97           RARE RABBIT               Men Leather Flat Boots   \n",
       "98             J.FONTINI  Men Textured Leather Formal Loafers   \n",
       "99       PUMA Motorsport         Women BMW M Motorsport Shoes   \n",
       "\n",
       "               Price  \n",
       "0          Rs. 11999  \n",
       "1           Rs. 6999  \n",
       "2   Rs. 8099Rs. 8999  \n",
       "3          (10% OFF)  \n",
       "4          Rs. 10999  \n",
       "..               ...  \n",
       "95  Rs. 8999Rs. 9999  \n",
       "96         (10% OFF)  \n",
       "97          Rs. 6999  \n",
       "98          Rs. 9999  \n",
       "99          Rs. 7999  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = 1\n",
    "Brand=[]\n",
    "Price=[]\n",
    "Description=[]\n",
    "\n",
    "while (counter <=4):\n",
    "    brand=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h3\")\n",
    "    for i in brand:\n",
    "        Brand.append(i.text)\n",
    "\n",
    "    description=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']//h4[@class='product-product']\")\n",
    "    for i in description:\n",
    "        Description.append(i.text)\n",
    "\n",
    "    price=driver.find_elements_by_xpath(\"//div[@class='product-price']/span\")\n",
    "    for i in price:\n",
    "        Price.append(i.text)\n",
    "\n",
    "    if (counter>100):\n",
    "            break\n",
    "    else:\n",
    "            counter += 1 \n",
    "    page_count += 1\n",
    "    driver.find_elements(By.XPATH,\"//li[@class='pagination-active']/a\")[-1].click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "shoe=pd.DataFrame({})\n",
    "shoe['Brand']=Brand[:100]\n",
    "shoe['Description']=Description[:100]\n",
    "shoe['Price']=Price[:100]\n",
    "shoe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q10: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the below image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first connect to the web driver through chromedriver.exe which is prsent in downlod file\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "url='https://www.amazon.in/s?k=Laptop&ref=nb_sb_noss_2'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "ElementNotInteractableException",
     "evalue": "Message: element not interactable\n  (Session info: chrome=93.0.4577.63)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementNotInteractableException\u001b[0m           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-741a6ccbb724>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msearch_job\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_class_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'nav-fill'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msearch_job\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Laptop\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msearch_btn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//button[@class='nav-search-submit nav-sprite']\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msearch_btn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_class_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'nav-search-submit nav-sprite'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msearch_btn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36msend_keys\u001b[1;34m(self, *value)\u001b[0m\n\u001b[0;32m    475\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_upload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m         self._execute(Command.SEND_KEYS_TO_ELEMENT,\n\u001b[0m\u001b[0;32m    478\u001b[0m                       {'text': \"\".join(keys_to_typing(value)),\n\u001b[0;32m    479\u001b[0m                        'value': keys_to_typing(value)})\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    631\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 633\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mElementNotInteractableException\u001b[0m: Message: element not interactable\n  (Session info: chrome=93.0.4577.63)\n"
     ]
    }
   ],
   "source": [
    "search_job=driver.find_element_by_class_name('nav-fill')\n",
    "search_job.send_keys(\"Laptop\")\n",
    "search_btn=driver.find_elements_by_xpath(\"//button[@class='nav-search-submit nav-sprite']\")\n",
    "search_btn=driver.find_element_by_class_name('nav-search-submit nav-sprite')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i7':\n",
    "        i.click()\n",
    "        break\n",
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i9':\n",
    "        i.click()\n",
    "        break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comp Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP Envy 11th Gen Core i7 Processor 13.3-inch (...</td>\n",
       "      <td>1,23,550</td>\n",
       "      <td>4.1 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo IdeaPad S540 11th Gen Intel Core i7 13....</td>\n",
       "      <td>77,990</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>57,990</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo IdeaPad Gaming 3 Intel Core i7 10th Gen...</td>\n",
       "      <td>73,990</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS ROG G703GI-E5148T 17.3\" (43.94 cms) FHD 1...</td>\n",
       "      <td>5,56,524</td>\n",
       "      <td>3.9 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS TUF Dash F15 (2021), 15.6-inch (39.62 cms...</td>\n",
       "      <td>87,990</td>\n",
       "      <td>3.8 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS TUF Gaming F17 (2021), 17.3-inch (43.94 c...</td>\n",
       "      <td>1,13,990</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel Core i7 13.3” (33....</td>\n",
       "      <td>1,07,990</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...</td>\n",
       "      <td>86,990</td>\n",
       "      <td>4.1 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP Pavilion 13(2021) 11th Gen Intel Core i7 La...</td>\n",
       "      <td>91,990</td>\n",
       "      <td>5 out of 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Comp Title     Price        Rating\n",
       "0  HP Envy 11th Gen Core i7 Processor 13.3-inch (...  1,23,550  4.1 out of 5\n",
       "1  Lenovo IdeaPad S540 11th Gen Intel Core i7 13....    77,990  4.3 out of 5\n",
       "2  Mi Notebook Horizon Edition 14 Intel Core i7-1...    57,990  4.2 out of 5\n",
       "3  Lenovo IdeaPad Gaming 3 Intel Core i7 10th Gen...    73,990  4.4 out of 5\n",
       "4  ASUS ROG G703GI-E5148T 17.3\" (43.94 cms) FHD 1...  5,56,524  3.9 out of 5\n",
       "5  ASUS TUF Dash F15 (2021), 15.6-inch (39.62 cms...    87,990  3.8 out of 5\n",
       "6  ASUS TUF Gaming F17 (2021), 17.3-inch (43.94 c...  1,13,990             -\n",
       "7  Fujitsu UH-X 11th Gen Intel Core i7 13.3” (33....  1,07,990  4.2 out of 5\n",
       "8  Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...    86,990  4.1 out of 5\n",
       "9  HP Pavilion 13(2021) 11th Gen Intel Core i7 La...    91,990    5 out of 5"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_titles=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "Company_titles=[]\n",
    "for i in company_titles:\n",
    "    Company_titles.append(i.text)\n",
    "\n",
    "price=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "Price=[]\n",
    "for i in price:\n",
    "    Price.append(i.text)\n",
    "\n",
    "#below code is to obtain rating\n",
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\"):\n",
    "    urls.append(i.get_attribute(\"href\"))\n",
    "\n",
    "Rating=[]\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        rating=driver.find_element_by_xpath(\"//span[@class='a-size-base a-nowrap']\")\n",
    "        Rating.append(rating.text.replace(\"/n\",\"new line\"))\n",
    "    except:\n",
    "        Rating.append(\"-\")\n",
    "Laptop=pd.DataFrame({})\n",
    "Laptop['Comp Title']=Company_titles[:10]\n",
    "Laptop['Price']=Price[:10]\n",
    "Laptop['Rating']=Rating[:10]\n",
    "Laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
